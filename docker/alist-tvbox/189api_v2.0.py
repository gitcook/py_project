import asyncio
import re
import os
import sqlite3
import aiohttp
import sys
import traceback
import time
import logging
from logging.handlers import TimedRotatingFileHandler
from urllib.parse import urlparse
from datetime import datetime, timezone, timedelta

# Telegram åº“
from telethon import TelegramClient
from telethon.sessions import StringSession
from telethon.tl.types import MessageEntityTextUrl
from telethon.tl.functions.messages import ImportChatInviteRequest
from telethon.tl.functions.channels import JoinChannelRequest
from telethon.errors import ChannelPrivateError

# ==============================================================================
# ====== ğŸ› ï¸ ç”¨æˆ·æ ¸å¿ƒé…ç½®åŒºåŸŸ (User Settings) =====================================
# ==============================================================================

# --- 1. Telegram é…ç½® (Telegram Settings) ---
API_ID = 27335138
API_HASH = '2459555ba95421148c682e2dc3031bb6'
STRING_SESSION = '' #å¡«ä½ è‡ªå·±çš„tg session

# --- 2. Alist-TVBox æ¥å£é…ç½® (Alist-TVBox Settings) ---
ALIST_URL = "http://192.168.2.1:4567/api/shares/"   #æ”¹ä½ è‡ªå·±çš„Alist-TVBoxåœ°å€
ALIST_KEY = ""       #æ”¹ä½ è‡ªå·±çš„TvBox API Key

# --- 3. äº‘ç›˜æŠ“å–å¼€å…³ (Cloud Drive Switches) ---
ENABLE_189 = True    # å¤©ç¿¼äº‘ç›˜ (189) - é»˜è®¤å¼€å¯
ENABLE_UC  = False   # UCç½‘ç›˜ - é»˜è®¤å…³é—­ï¼Œæ²¡åšé€‚é…ä¸ä¿è¯èƒ½ç”¨
ENABLE_123 = False   # 123ç½‘ç›˜ - é»˜è®¤å…³é—­ï¼Œæ²¡åšé€‚é…ä¸ä¿è¯èƒ½ç”¨

# --- 4. è¿è¡Œç¯å¢ƒä¸æ‰«æé…ç½® (Environment & Scan Settings) ---
SAVE_PATH = "/mnt/alist-tvbox"     # æ”¹ä½ è‡ªå·±çš„æ•°æ®åº“ä¿å­˜è·¯å¾„
LOOP_SWITCH = 2                    # 1 = å¾ªç¯ç›‘æ§(å¸¸é©»), 2 = å•æ¬¡è¿è¡Œ(è·‘å®Œé€€å‡º)
MONITOR_INTERVAL_HOURS = 3         # å¾ªç¯æ¨¡å¼ä¸‹çš„é—´éš”æ—¶é—´ (å•ä½: å°æ—¶)
MAX_CONCURRENT_REQUESTS = 10       # æ¨é€å¹¶å‘çº¿ç¨‹æ•°

# [å…¨å±€æ‰«æå‚æ•°]
MONITOR_LIMIT = 3000               # æ¯ä¸ªé¢‘é“æœ€å¤§æ‰«ææ¶ˆæ¯æ•°
MONITOR_DAYS = 365                 # æœ€å¤§å›æº¯å¤©æ•°
SMART_STOP_COUNT = 50              # [æ™ºèƒ½ä¸­æ–­] è¿ç»­å¤šå°‘æ¡æ—§æ¶ˆæ¯ååœæ­¢æ‰«æ
DB_RETENTION_DAYS = 30             # [æ–°å¢] æ•°æ®åº“ä¿ç•™å¤©æ•°

# --- 5. ç›‘æ§é¢‘é“åˆ—è¡¨ (Channel List) ---
CHANNEL_URLS = [
    'https://t.me/tianyirigeng',
    'https://t.me/cloudtianyi'
]

# --- 6. å…¨å±€å…³é”®è¯è¿‡æ»¤ (Global Exclude Keywords) ---
EXCLUDE_KEYWORDS = [
    'å°ç¨‹åº', 'é¢„å‘Š', 'é¢„æ„Ÿ', 'ç›ˆåˆ©', 'å³å¯è§‚çœ‹', 'ä¹¦ç±', 'ç”µå­ä¹¦', 'å›¾ä¹¦', 'ä¸›ä¹¦', 'æœŸåˆŠ','app','è½¯ä»¶', 
    'ç ´è§£ç‰ˆ','è§£é”','ä¸“ä¸šç‰ˆ','é«˜çº§ç‰ˆ','æœ€æ–°ç‰ˆ','é£Ÿè°±', 'å…å®‰è£…', 'å…å¹¿å‘Š','å®‰å“', 'Android', 'è¯¾ç¨‹', 
    'ä½œå“', 'æ•™ç¨‹', 'æ•™å­¦', 'å…¨ä¹¦', 'åè‘—', 'mobi', 'MOBI', 'epub','ä»»å¤©å ‚','PC','å•æœºæ¸¸æˆ',
    'pdf', 'PDF', 'PPT', 'æŠ½å¥–', 'å®Œæ•´ç‰ˆ', 'æœ‰å£°ä¹¦','è¯»è€…','æ–‡å­¦', 'å†™ä½œ', 'èŠ‚è¯¾', 'å¥—è£…', 'è¯æœ¯', 
    'çº¯å‡€ç‰ˆ', 'æ—¥å†', 'txt', 'MP3','ç½‘èµš', 'mp3', 'WAV', 'CD', 'éŸ³ä¹', 'ä¸“è¾‘', 'æ¨¡æ¿', 'ä¹¦ä¸­', 
    'è¯»ç‰©', 'å…¥é—¨', 'é›¶åŸºç¡€', 'å¸¸è¯†', 'ç”µå•†', 'å°çº¢ä¹¦','JPG','çŸ­è§†é¢‘','å·¥ä½œæ€»ç»“', 'å“ˆå“ˆå“ˆå“ˆå“ˆ', 
    'å†™çœŸ','æŠ–éŸ³', 'èµ„æ–™', 'åä¸º', 'çŸ­å‰§', 'çºªå½•ç‰‡', 'è®°å½•ç‰‡', 'çºªå½•', 'çºªå®', 'å­¦ä¹ ', 'ä»˜è´¹', 
    'å°å­¦', 'åˆä¸­','æ•°å­¦', 'è¯­æ–‡', 'å”è¯—','é­”æ³•åå¥³å·«','è½¦è½½','DJ','åˆå¹¶', 'æ¼”å”±ä¼š', 'ç»¼è‰º'
]

# --- 7. åˆ†ç±»æŠ“å–è§„åˆ™ (Rules Config) ---
API_CONFIGS = [
    # 0: å‰§é›† (ä¼˜å…ˆåŒ¹é…)
    {
        'name': "TV Show", 
        'folder_prefix': "å‰§é›†/",
        'priority_keywords': ["æƒåŠ›çš„æ¸¸æˆ", "ç»å‘½æ¯’å¸ˆ", "è‹ç©¹æµ©ç€š", "ä¸‡ç‰©ç”Ÿçµ"],  #ç‰¹æƒå…³é”®è¯ï¼Œç›´æ¥æœç´¢tgé¢‘é“ç›¸å…³å…³é”®è¯ã€‚
        'required_keywords': [], #å¿…é€‰å…³é”®è¯
        'optional_keywords': ["å­£", "é›†", "EP", "S0", "ç¾å‰§", "è‹±å‰§", "å›½äº§å‰§", "æ—¥å‰§", "éŸ©å‰§"], #å¯é€‰å…³é”®è¯
        'excluded_keywords': ["P5", "Profile 5", "Profile5", "DV P5", "DVP5"], #æ’é™¤å…³é”®è¯
        'try_join': True
    },
    # 1: ç”µå½± (å‰§é›†æœªåŒ¹é…æ—¶åŒ¹é…æ­¤è§„åˆ™)
    {
        'name': "Movies",    
        'folder_prefix': "ç”µå½±/",
        'priority_keywords': [],
        'required_keywords': [], 
        'optional_keywords': ["åŸç›˜", "ç®€ç¹", "ç®€è‹±", "ç®€ä¸­", "åŒè¯­", "REMUX", "4K", "4KSDR", "SDR", "HD", "HDR", "60 FPS", "60 å¸§", "è‡»å½©", "é«˜ç ", "ç”µå½±"],
        'excluded_keywords': ["æªç‰ˆ", "æŠ¢å…ˆç‰ˆ", "TS", "TC", "1080", "1080p", "P5", "Profile 5", "Profile5", "DV P5", "DVP5"], 
        'try_join': True
    }
]

# --- 8. ä»£ç†é…ç½® (Proxy Settings) ---
ENABLE_PROXY = False                       
PROXY_URL = "socks5://192.168.2.1:7891"

# ==============================================================================
# ====== ğŸ“Š ä»ªè¡¨ç›˜ UI æ¨¡å— (Dashboard UI Module) ================================
# ==============================================================================

class Dashboard:
    """è´Ÿè´£æ§åˆ¶å°è¡¨æ ¼è¾“å‡ºï¼Œåƒç´ çº§å¯¹é½ (æ€»å®½80å­—ç¬¦)"""
    
    # åˆ—å®½é…ç½®: Channel/Project(16) | Progress(13) | Found(13) | Added(13) | Time(13)
    HEADER_FMT = "{:<16} | {:>13} | {:>13} | {:>13} | {:>13}"
    ROW_FMT    = "{:<16} | {:>13} | {:>13} | {:>13} | {:>13}"
    
    @staticmethod
    def print_header():
        print("="*80)
        print(Dashboard.HEADER_FMT.format("Channel/Project", "Progress", "Found", "Added", "Time"))
        print("-" * 80)

    @staticmethod
    def print_channel_frame(channel_name, total, current, stats, start_time, is_final=False):
        """ç»˜åˆ¶ä¿¡æ¯"""
        # è®¡ç®—è€—æ—¶
        duration_str = "-"
        if start_time:
            elapsed = datetime.now() - start_time
            mm, ss = divmod(elapsed.seconds, 60)
            duration_str = f"{mm:02d}m {ss:02d}s"
        
        # æˆªæ–­é¢‘é“å
        safe_name = channel_name[:16]

        # è¿›åº¦å­—ç¬¦ä¸²å¤„ç†
        progress_str = "-"
        if isinstance(total, int) and isinstance(current, int):
            if total == -1: 
                progress_str = "-"
            else:
                progress_str = f"{current}/{total}"
        elif isinstance(total, str): 
            progress_str = total
        
        # è®¡ç®—æ€»æ•°
        total_found = stats[0]['found'] + stats[1]['found'] + stats['special']['found']
        total_added = stats[0]['added'] + stats[1]['added'] + stats['special']['added']

        # --- ç¬¬1è¡Œ: é¢‘é“æ€»è§ˆ ---
        line1 = Dashboard.ROW_FMT.format(safe_name, progress_str[:13], str(total_found), str(total_added), duration_str)
        
        # --- ç¬¬2è¡Œ: å‰§é›† (API 0) ---
        s_found = stats[0]['found']
        s_added = stats[0]['added']
        line2 = Dashboard.ROW_FMT.format("  |_ TV Show", "-", str(s_found), str(s_added), "-")
        
        # --- ç¬¬3è¡Œ: ç”µå½± (API 1) ---
        m_found = stats[1]['found']
        m_added = stats[1]['added']
        line3 = Dashboard.ROW_FMT.format("  |_ Movies", "-", str(m_found), str(m_added), "-")

        # --- ç¬¬4è¡Œ: ç‰¹æƒæœç´¢ (Special) ---
        sp_found = stats['special']['found']
        sp_added = stats['special']['added']
        line4 = Dashboard.ROW_FMT.format("  |_ Special", "-", str(sp_found), str(sp_added), "-")

        # æ‰“å°å¹¶å¤„ç†å…‰æ ‡å›é€€
        print(f"\r{line1}\033[K\n{line2}\033[K\n{line3}\033[K\n{line4}\033[K", end="")
        
        if not is_final:
            sys.stdout.write("\033[F\033[F\033[F") 
            sys.stdout.flush()
        else:
            print() # å®Œæˆæ—¶æ¢è¡Œ

# ==============================================================================
# ====== ğŸ’» æ ¸å¿ƒé€»è¾‘ä»£ç  (Core Logic) ===========================================
# ==============================================================================

RE_ACCESS_CODE = re.compile(r'(?:å¯†ç |æå–ç |éªŒè¯ç |è®¿é—®ç |åˆ†äº«å¯†ç |å¯†é’¥|pwd|password|share_pwd|pass_code|#)[=:ï¼š\s]*([a-zA-Z0-9]{4,6})(?![a-zA-Z0-9])', re.IGNORECASE)
RE_URL_PARAM_CODE = re.compile(r'[?&](?:pwd|password|access_code|code|sharepwd)=([a-zA-Z0-9]{4,6})', re.IGNORECASE)
RE_TIANYI = re.compile(r'(?:https?://)?cloud\.189\.cn/t/([a-zA-Z0-9]{12})\b', re.IGNORECASE)
RE_UC = re.compile(r'drive\.uc\.cn/s/([a-zA-Z0-9\-_]+)([^#]*)?(#*/list/share/([^\?\-]+))?', re.IGNORECASE)
RE_123 = re.compile(r'(?:https?://)?(?:www\.)?(?:123[\d]*|pan\.123)\.com/s/([a-zA-Z0-9\-_]+)', re.IGNORECASE)

class SQLiteManager:
    def __init__(self, db_path):
        if db_path and not os.path.exists(db_path):
            try: os.makedirs(db_path, exist_ok=True)
            except: pass
        self.db_file = os.path.join(db_path, "189api.db") if db_path else "189api.db"
        self.conn = sqlite3.connect(self.db_file, check_same_thread=False)
        self.cursor = self.conn.cursor()
        self._init_db()
        self._migrate_db() 

    def _init_db(self):
        try:
            self.cursor.execute('''CREATE TABLE IF NOT EXISTS processed_msgs
                         (channel_id TEXT, msg_id INTEGER, api_index INTEGER, 
                          PRIMARY KEY (channel_id, msg_id, api_index))''')
            self.cursor.execute('''CREATE TABLE IF NOT EXISTS sent_links
                         (link TEXT, api_index INTEGER, 
                          PRIMARY KEY (link, api_index))''')
            self.conn.commit()
        except Exception as e:
            print(f"DB Error: {e}")

    def _migrate_db(self):
        try:
            self.cursor.execute("PRAGMA table_info(processed_msgs)")
            columns = [info[1] for info in self.cursor.fetchall()]
            if 'timestamp' not in columns:
                self.cursor.execute("ALTER TABLE processed_msgs ADD COLUMN timestamp REAL DEFAULT 0")
                self.conn.commit()
        except: pass

    def cleanup_old_records(self, days=30):
        try:
            cutoff = time.time() - (days * 86400)
            self.cursor.execute("DELETE FROM processed_msgs WHERE timestamp > 0 AND timestamp < ?", (cutoff,))
            self.conn.commit()
        except: pass

    def close(self):
        if self.conn: self.conn.close()

    def is_msg_processed(self, channel_id, msg_id):
        try:
            self.cursor.execute("SELECT 1 FROM processed_msgs WHERE channel_id=? AND msg_id=? LIMIT 1", (channel_id, msg_id))
            return self.cursor.fetchone() is not None
        except: return False

    def is_link_sent(self, link, api_index):
        try:
            self.cursor.execute("SELECT 1 FROM sent_links WHERE link=? AND api_index=?", (link, api_index))
            return self.cursor.fetchone() is not None
        except: return False

    def add_link(self, link, api_index):
        try:
            self.cursor.execute("INSERT OR IGNORE INTO sent_links VALUES (?,?)", (link, api_index))
            self.conn.commit()
        except: pass
            
    def bulk_add_msgs(self, data_list):
        if not data_list: return
        try:
            self.cursor.executemany("INSERT OR IGNORE INTO processed_msgs (channel_id, msg_id, api_index, timestamp) VALUES (?,?,?,?)", data_list)
            self.conn.commit()
        except: pass

class StringCleaner:
    # ä»…ç”¨äº"ä¸¢å¼ƒæ•´è¡Œ"çš„å…³é”®è¯ (ç»å¯¹åƒåœ¾)
    JUNK_KEYWORDS = [
        "ç¦åˆ©", "é¢‘é“", "å…³æ³¨", "ç½®é¡¶", "æ¨è", "via", "è½¬è‡ª", "æ¥æº", "æŠ•ç¨¿", "å°ç¼–", "æ•´ç†", "å¤±æ•ˆ", "è¡¥æ¡£",
        "ç¦è¨€", "é€šçŸ¥", "æ›´æ–°", "æ—¥æ›´", "å…¬ä¼—å·", "åŠ å…¥", "ç‚¹å‡»", "é¢†å–"
    ]
    AD_PATTERNS = [
        r'å¤©ç¿¼äº‘ç›˜.*èµ„æºåˆ†äº«', r'via\s*ğŸ¤–ç·¨è™Ÿ\s*9527', r'ğŸ·?\s*æ ‡ç­¾\s*ï¼š.*', r'[ğŸ·#]\s*\w+',
        r'UCç½‘ç›˜.*åˆ†äº«', r'èµ„æºç¼–å·ï¼š\d+', r'123ç½‘ç›˜.*åˆ†äº«', r'https?://\S+', 
        r'[a-zA-Z0-9]+\.(cn|com|net)/\S+'
    ]

    @staticmethod
    def clean(text):
        if not text: return ""
        for p in StringCleaner.AD_PATTERNS:
            text = re.sub(p, '', text, flags=re.IGNORECASE)
        text = re.sub(r'https?://\S+', '', text)
        text = re.sub(r'[@#]\S+', '', text)
        # ç§»é™¤ Emoji
        text = re.sub(r'[\U00010000-\U0010ffff]', '', text) 
        # ä¿ç•™æŠ€æœ¯ç¬¦å· (& + / _)
        text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9,ï¼Œ.ã€‚!ï¼?ï¼Ÿ:ï¼šã€Šã€‹()ï¼ˆï¼‰ã€ã€‘\+\-\s\u3000&/_]', ' ', text)
        return text.strip()[:195]

    @staticmethod
    def is_junk_line(line):
        line = line.strip()
        if len(line) < 2: return True
        for kw in StringCleaner.JUNK_KEYWORDS:
            if kw in line: return True
        if re.match(r'^[\d\s\.\-\*]+$', line): return True
        return False

def get_channel_id(url):
    return re.sub(r'[^\w\-]', '_', re.sub(r'https?://', '', url))[:50]

class CloudMonitor:
    def __init__(self):
        self.db = SQLiteManager(SAVE_PATH)
        self.client = None
        self.sem = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
        self.session_sent_links = set()
        self._init_logging()

    def _init_logging(self):
        if SAVE_PATH and not os.path.exists(SAVE_PATH):
            try: os.makedirs(SAVE_PATH, exist_ok=True)
            except: pass
        log_file = os.path.join(SAVE_PATH, "189api_error.log") if SAVE_PATH else "189api_error.log"
        self.logger = logging.getLogger('189api')
        self.logger.setLevel(logging.ERROR)
        if not self.logger.handlers:
            handler = TimedRotatingFileHandler(log_file, when='midnight', interval=1, backupCount=30, encoding='utf-8')
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)

    async def start(self):
        self.db.cleanup_old_records(DB_RETENTION_DAYS)
        
        proxy_params = None
        if ENABLE_PROXY:
            try:
                import socks
                parsed = urlparse(PROXY_URL)
                if 'socks5' in parsed.scheme: p_type = socks.SOCKS5
                elif 'socks4' in parsed.scheme: p_type = socks.SOCKS4
                else: p_type = socks.HTTP
                proxy_params = (p_type, parsed.hostname, parsed.port, True, parsed.username, parsed.password)
            except Exception as e: 
                print("Proxy Config Error")
                self.logger.error(f"Proxy Config Error: {e}")
                return
        
        try:
            client_params = {'session': StringSession(STRING_SESSION), 'api_id': API_ID, 'api_hash': API_HASH}
            if proxy_params: client_params['proxy'] = proxy_params
            self.client = TelegramClient(**client_params)
            await self.client.start()
        except Exception as e:
            print(f"Connect Failed: {e}")
            self.logger.error(f"Telegram Connect Failed: {e}")
            self.db.close()
            return

        try:
            async with aiohttp.ClientSession() as session:
                if LOOP_SWITCH == 1:
                    while True:
                        self.session_sent_links.clear() 
                        await self.run_cycle(session)
                        await asyncio.sleep(MONITOR_INTERVAL_HOURS * 3600)
                else:
                    await self.run_cycle(session)
        finally:
            await self.client.disconnect()
            self.db.close()

    async def run_cycle(self, session):
        Dashboard.print_header()
        for channel_url in CHANNEL_URLS:
            try:
                await self.process_channel_unified(session, channel_url)
                print("-" * 80)
            except Exception as e:
                print(f"\nâŒ {channel_url} Error: {e}")
                self.logger.error(f"Run Cycle Error for {channel_url}: {traceback.format_exc()}")
                print("-" * 80)

    async def process_channel_unified(self, session, channel_url):
        channel_name = channel_url.split('/')[-1]
        channel_id = get_channel_id(channel_url)
        
        stats = {
            0: {'found': 0, 'added': 0},
            1: {'found': 0, 'added': 0},
            'special': {'found': 0, 'added': 0}
        }
        
        start_time = datetime.now()
        Dashboard.print_channel_frame(channel_name, 0, 0, stats, start_time)

        try:
            any_try_join = any(cfg.get('try_join', False) for cfg in API_CONFIGS)
            entity = await self.get_entity_safe(channel_url, any_try_join)
            
            if not entity:
                Dashboard.print_channel_frame(channel_name, -1, -1, stats, start_time, is_final=True)
                self.logger.error(f"Channel not found or cannot join: {channel_url}")
                return

            # --- Phase 1: Standard Scan ---
            min_date = datetime.now(timezone.utc) - timedelta(days=MONITOR_DAYS)
            messages = []
            fetch_count = 0
            consecutive_old_count = 0 
            
            try:
                async for msg in self.client.iter_messages(entity, limit=MONITOR_LIMIT):
                    if msg.date < min_date: break
                    
                    if self.db.is_msg_processed(channel_id, msg.id):
                        consecutive_old_count += 1
                        if consecutive_old_count >= SMART_STOP_COUNT: break
                    else:
                        consecutive_old_count = 0

                    messages.append(msg)
                    fetch_count += 1
                    if fetch_count % 50 == 0:
                        Dashboard.print_channel_frame(channel_name, MONITOR_LIMIT, fetch_count, stats, start_time)
                        
            except ChannelPrivateError: 
                self.logger.error(f"Access Denied (Private) for channel: {channel_url}")
            
            if messages:
                await self._process_message_batch(session, messages, channel_name, channel_id, stats, start_time)

            # --- Phase 2: Priority Search ---
            Dashboard.print_channel_frame(channel_name, 0, 0, stats, start_time)

            for api_idx, cfg in enumerate(API_CONFIGS):
                priorities = cfg.get('priority_keywords', [])
                if not priorities: continue
                
                for keyword in priorities:
                    search_msgs = []
                    try:
                        async for msg in self.client.iter_messages(entity, search=keyword, limit=500):
                            search_msgs.append(msg)
                    except Exception as e:
                        self.logger.error(f"Search Error '{keyword}': {e}")
                    
                    if search_msgs:
                        await self._process_message_batch(
                            session, search_msgs, channel_name, channel_id, stats, start_time, 
                            restrict_to_api_idx=api_idx
                        )

            Dashboard.print_channel_frame(channel_name, MONITOR_LIMIT, fetch_count, stats, start_time, is_final=True)

        except Exception as e:
            self.logger.error(f"Process Channel Error {channel_name}: {traceback.format_exc()}")
            Dashboard.print_channel_frame(channel_name, -1, -1, stats, start_time, is_final=True)

    async def _process_message_batch(self, session, messages, channel_name, channel_id, stats, start_time, restrict_to_api_idx=None):
        tasks = []
        msgs_to_save = []
        now_ts = time.time()
        
        current_idx = 0
        total_len = len(messages)

        for msg in messages:
            current_idx += 1
            if current_idx % 20 == 0:
                Dashboard.print_channel_frame(channel_name, total_len, current_idx, stats, start_time)

            if not msg.text: continue

            is_spam = False
            for kw in EXCLUDE_KEYWORDS:
                if kw in msg.text: 
                    is_spam = True; break
            if is_spam: continue

            cloud_infos = self.extract_links(msg)
            if not cloud_infos: continue
            
            msgs_to_save.append((channel_id, msg.id, 0, now_ts))

            for info in cloud_infos:
                matched_rule = False 
                
                for api_idx, api_cfg in enumerate(API_CONFIGS):
                    if restrict_to_api_idx is not None and api_idx != restrict_to_api_idx:
                        continue
                    if matched_rule: break
                    
                    if (info['link'], api_idx) in self.session_sent_links:
                        matched_rule = True; break

                    if self.db.is_link_sent(info['link'], api_idx): 
                        matched_rule = True; break

                    is_priority_hit = self.check_api_keywords(msg.text, api_cfg)
                    if not is_priority_hit: continue

                    check_content = info['desc']
                    if not self.check_api_excludes(check_content, api_cfg): continue

                    matched_rule = True
                    stats[api_idx]['found'] += 1
                    
                    priority_kws = api_cfg.get('priority_keywords', [])
                    is_special_hit = False
                    if priority_kws and any(k in msg.text for k in priority_kws):
                        stats['special']['found'] += 1
                        is_special_hit = True

                    task_name = self.build_task_name(info, api_cfg.get('folder_prefix', ''))
                    payload = {
                        "path": task_name, "shareId": info['code'],
                        "folderId": "", "password": info['pwd'] or "", "type": info['type_id']
                    }
                    
                    self.session_sent_links.add((info['link'], api_idx))
                    tasks.append(self.push_wrapper(session, payload, info, msg.id, api_idx, is_special_hit, channel_name, total_len, current_idx, stats, start_time))
        
        if tasks:
            Dashboard.print_channel_frame(channel_name, total_len, total_len, stats, start_time)
            await asyncio.gather(*tasks)
        
        self.db.bulk_add_msgs(msgs_to_save)

    async def push_wrapper(self, session, payload, info, msg_id, api_idx, is_special_hit, channel_name, total, current, stats, start_time):
        success, resp = await self.send_to_api(session, payload)
        if success:
            stats[api_idx]['added'] += 1
            if is_special_hit:
                stats['special']['added'] += 1
            self.db.add_link(info['link'], api_idx)
            Dashboard.print_channel_frame(channel_name, total, current, stats, start_time)
        elif resp != "Exists":
            self.logger.error(f"Push Failed [{resp}] for {info['desc']}: {info['link']}")

    async def send_to_api(self, session, payload):
        async with self.sem: 
            headers = {"x-api-key": ALIST_KEY, "Content-Type": "application/json", "Authorization": ALIST_KEY}
            for attempt in range(3): 
                try:
                    async with session.post(ALIST_URL, json=payload, headers=headers, timeout=20) as resp:
                        if resp.status == 200: return True, ""
                        if resp.status == 400: return False, "Exists" 
                        if resp.status >= 500: 
                            await asyncio.sleep(1); continue
                        return False, f"HTTP {resp.status}"
                except Exception as e:
                    if attempt == 2:
                        self.logger.error(f"API Network Error: {e}")
                    if attempt < 2: await asyncio.sleep(1)
                    else: return False, "NetErr"
            return False, "MaxRetries"

    async def get_entity_safe(self, url, try_join):
        try: return await self.client.get_entity(url)
        except:
            if '+' in url and try_join:
                try:
                    await self.client(ImportChatInviteRequest(url.split('+')[-1]))
                    return await self.client.get_entity(url)
                except Exception as e:
                    self.logger.error(f"Join Channel Failed {url}: {e}")
                    pass
        return None

    def check_api_excludes(self, text, cfg):
        local_exclude = cfg.get('excluded_keywords', [])
        if local_exclude:
            for kw in local_exclude:
                if re.match(r'^[a-zA-Z0-9]+$', kw):
                    if re.search(rf'\b{re.escape(kw)}\b', text, re.IGNORECASE): return False
                else:
                    if kw in text: return False
        return True

    def check_api_keywords(self, text, cfg):
        priority = cfg.get('priority_keywords', [])
        hit_priority = False
        if priority and any(k in text for k in priority):
            hit_priority = True
        
        req = cfg.get('required_keywords', [])
        if not hit_priority:
            if req and not all(k in text for k in req): return False
        
        opt = cfg.get('optional_keywords', [])
        if opt and not any(k in text for k in opt): return False
        return True

    def extract_links(self, msg):
        results = []
        text = msg.message.replace('%EF%BC%88', '(').replace('%EF%BC%89', ')')
        
        smart_title = "Untitled"
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        name_marker = re.search(r'(?:èµ„æº|æ–‡ä»¶)?(?:åç§°|å|ç‰‡å|Title)[ï¼š:]\s*(.+)', text)
        if name_marker:
            smart_title = StringCleaner.clean(name_marker.group(1))
        else:
            for line in lines:
                if StringCleaner.is_junk_line(line): continue
                cleaned = StringCleaner.clean(line)
                if len(cleaned) > 2: 
                    smart_title = cleaned; break

        m_pwd = RE_ACCESS_CODE.search(text)
        global_pwd = m_pwd.group(1) if m_pwd else None
        
        patterns = []
        if ENABLE_189: patterns.append((RE_TIANYI, 'tianyi', 9, "https://cloud.189.cn/t/"))
        if ENABLE_UC:  patterns.append((RE_UC, 'uc', 7, "https://drive.uc.cn/s/"))
        if ENABLE_123: patterns.append((RE_123, '123', 3, "https://www.123865.com/s/"))

        items = []
        for p, ctype, cid, prefix in patterns:
            for m in p.finditer(text):
                items.append({'code': m.group(1), 'type': ctype, 'tid': cid, 'prefix': prefix, 'ent': False, 'm': m})
        if msg.entities:
            for ent in msg.entities:
                if isinstance(ent, MessageEntityTextUrl):
                    for p, ctype, cid, prefix in patterns:
                        m = p.search(ent.url)
                        if m:
                            items.append({'code': m.group(1), 'type': ctype, 'tid': cid, 'prefix': prefix, 'ent': True, 'desc': text[ent.offset:ent.offset+ent.length], 'url': ent.url})

        unique_codes = set(item['code'] for item in items)
        is_multi_link = len(unique_codes) > 1
        
        # [æ ¸å¿ƒä¿®æ”¹] å¤šé“¾æ¥åŸºç¡€æ ‡é¢˜æ¸…æ´—
        if is_multi_link:
            base_title = re.sub(r'(?i)\b(?:4K|1080[Pp]?|2160[Pp]?|SDR|HDR\d*\+?|DV|Dolby\s*Vision)(?:[\s&/+\\]+(?:4K|1080[Pp]?|2160[Pp]?|SDR|HDR\d*\+?|DV|Dolby\s*Vision))*\b', '', smart_title)
            base_title = re.sub(r'\s+', ' ', base_title).strip()
        else:
            base_title = smart_title

        seen = set()
        for it in items:
            if it['code'] in seen: continue
            seen.add(it['code'])
            
            pwd = global_pwd
            url_check = it.get('url', it.get('m').group(0) if not it.get('ent') else "")
            url_pwd = RE_URL_PARAM_CODE.search(url_check)
            if url_pwd: pwd = url_pwd.group(1)

            local_desc = ""
            if it.get('ent'):
                d = StringCleaner.clean(it['desc'])
                if len(d) > 1: local_desc = d
            else:
                start = it['m'].start()
                context = text[:start]
                prev_lines = context.split('\n')
                for i in range(len(prev_lines) - 1, -1, -1):
                    line = prev_lines[i].strip()
                    if not line: continue
                    cleaned_line = StringCleaner.clean(line)
                    if not cleaned_line or StringCleaner.is_junk_line(cleaned_line): continue
                    
                    # [æ ¸å¿ƒä¿®æ”¹] å¦‚æœæ˜¯å¤šé“¾æ¥ï¼Œå¼ºåˆ¶ä¿¡ä»»æœ¬åœ°æ ‡ç­¾ï¼Œå¿½ç•¥é˜²é‡æ£€æŸ¥
                    if is_multi_link:
                        local_desc = cleaned_line
                        break
                    else:
                        # å•é“¾æ¥ä¿æŒé˜²é‡é€»è¾‘
                        if smart_title not in cleaned_line and cleaned_line not in smart_title:
                             local_desc = cleaned_line
                        break

            # æ‹¼æ¥
            if is_multi_link:
                final_desc = f"{base_title} {local_desc}" if local_desc else base_title
            else:
                final_desc = smart_title

            results.append({
                'type': it['type'], 'type_id': it['tid'], 'code': it['code'],
                'link': f"{it['prefix']}{it['code']}", 'pwd': pwd, 
                'desc': final_desc
            })
        return results

    def build_task_name(self, info, prefix):
        return f"{prefix}{info['desc']}_{info['code'][-4:]}"[:200]

if __name__ == '__main__':
    monitor = CloudMonitor()
    try: asyncio.run(monitor.start())
    except KeyboardInterrupt: print("\nStopped by user")